# Signature Router & Management System - Epic Breakdown

**Author:** BMAD Product Manager  
**Date:** 2025-11-26  
**Version:** 1.0  
**Context:** Created from PRD + Complete Architecture  

---

## Overview

Este documento descompone el PRD de **Signature Router & Management System** en √©picas implementables con historias de usuario detalladas. Cada √©pica entrega valor de negocio tangible y est√° lista para implementaci√≥n en Phase 4 (Development Sprints).

**Contexto Incorporado**:
- ‚úÖ **PRD**: 90 Functional Requirements + 47 Non-Functional Requirements
- ‚úÖ **Architecture**: Hexagonal + DDD + Event-Driven + Resilience patterns
- ‚úÖ **Tech Stack**: Spring Boot 3 + PostgreSQL 15 + Kafka + React 18

**Living Document**: Este documento puede ser actualizado durante implementaci√≥n con aprendizajes o ajustes de alcance.

---

## Epic Summary

| Epic # | Epic Name | Goal | Story Count | FRs Covered |
|--------|-----------|------|-------------|-------------|
| **E1** | Foundation & Infrastructure | Establecer base t√©cnica para todos los servicios | 8 stories | Infrastructure for all FRs |
| **E2** | Signature Request Orchestration | Usuarios pueden solicitar firmas con routing inteligente | 12 stories | FR1-FR10, FR11-FR19, FR20-FR28 |
| **E3** | Multi-Provider Integration | Sistema env√≠a challenges por m√∫ltiples canales con fallback | 10 stories | FR20-FR28, FR29-FR38 |
| **E4** | Resilience & Circuit Breaking | Sistema maneja fallos gracefully con degraded mode | 8 stories | FR29-FR38, NFR-A4-A7 |
| **E5** | Event-Driven Architecture | Eventos de dominio publicados a Kafka para consumers | 7 stories | FR39-FR46 |
| **E6** | Admin Portal - Rule Management | Admins gestionan routing rules con SpEL visualmente | 10 stories | FR47-FR56 |
| **E7** | Admin Portal - Monitoring & Ops | Admins monitorean providers y visualizan routing timelines | 9 stories | FR57-FR72 |
| **E8** | Security & Compliance | Cumplir compliance bancario (PCI-DSS, GDPR, SOC 2) | 8 stories | FR73-FR90, NFR-S1-S16 |
| **E9** | Observability & SLO Tracking | M√©tricas, logs, traces para SLO ‚â•99.9% y P99 <300ms | 6 stories | NFR-O1-O14, NFR-P1-P10 |

**Total**: 9 Epics, ~78 Stories

---

## Functional Requirements Inventory (from PRD)

### FR Group 1: Signature Request Management (FR1-FR10)
- FR1: Recibir solicitudes con contexto JSONB inmutable
- FR2: Generar UUIDv7 ordenables temporalmente
- FR3: Almacenar customer_id pseudonimizado
- FR4: Generar SHA-256 hash del contexto
- FR5: Establecer TTL default 3 minutos
- FR6: Consultar estado de signature request
- FR7: Proporcionar routing timeline completo
- FR8: Abortar signature requests manualmente
- FR9: Expirar autom√°ticamente al alcanzar TTL
- FR10: Detectar y rechazar duplicados (idempotency)

### FR Group 2: Routing Decision Engine (FR11-FR19)
- FR11: Evaluar expresiones SpEL contra contexto
- FR12: Aplicar reglas por prioridad (short-circuit)
- FR13: Seleccionar canal √≥ptimo
- FR14: Registrar qu√© regla determin√≥ routing
- FR15: Manejar reglas sin coincidencias (default)
- FR16: Validar sintaxis SpEL pre-persistencia
- FR17: Deshabilitar/habilitar reglas
- FR18: Reordenar prioridades
- FR19: Metadata de auditor√≠a (qui√©n cre√≥/modific√≥)

### FR Group 3: Challenge Delivery (FR20-FR28)
- FR20: Enviar challenges SMS v√≠a Twilio
- FR21: Enviar push notifications
- FR22: Realizar llamadas de voz
- FR23: Almacenar provider_challenge_id
- FR24: Almacenar provider_proof (non-repudiation)
- FR25: Aplicar timeouts configurables
- FR26: Registrar timestamps de env√≠o/respuesta
- FR27: Un solo challenge activo por request
- FR28: Expirar challenges sin respuesta

### FR Group 4: Fallback & Resilience (FR29-FR38)
- FR29: Detectar fallos de providers autom√°ticamente
- FR30: Intentar fallback a canal alternativo
- FR31: Crear nuevo challenge por cada fallback
- FR32: Retry con exponential backoff (max 3)
- FR33: Calcular error rate por provider
- FR34: Activar circuit breaker >50% error rate
- FR35: Pausar provider en degraded mode (5 min)
- FR36: Reactivar provider autom√°ticamente
- FR37: Prevenir loops infinitos (max 3 canales)
- FR38: Marcar como FAILED si todos fallan

### FR Group 5: Event Publishing (FR39-FR46)
- FR39: Persistir eventos en outbox table
- FR40: Garantizar atomicidad (estado + evento, misma TX)
- FR41: Publicar eventos a Kafka v√≠a Debezium CDC
- FR42: Serializar eventos en Avro con schema validation
- FR43: Particionar eventos por aggregate_id
- FR44: Incluir trace_id en eventos
- FR45: Publicar 8 tipos de eventos de dominio
- FR46: Almacenar hash de transaction context

### FR Group 6-10: Admin Portal & Security (FR47-FR90)
- **FR47-FR56**: Admin Rule Management
- **FR57-FR64**: Admin Provider Management
- **FR65-FR72**: Admin Monitoring & Visualization
- **FR73-FR80**: Audit & Compliance
- **FR81-FR90**: Security & Access Control

---

## FR Coverage Map

| Epic | FRs Covered | Description |
|------|-------------|-------------|
| **E1: Foundation** | Infrastructure | Project setup, hexagonal structure, PostgreSQL, Kafka, Vault |
| **E2: Signature Orchestration** | FR1-FR28 | Complete signature request lifecycle + routing + challenge delivery |
| **E3: Multi-Provider** | FR20-FR28 | SMS (Twilio), Push, Voice provider implementations |
| **E4: Resilience** | FR29-FR38 | Circuit breaker, fallback chain, degraded mode, retry |
| **E5: Event-Driven** | FR39-FR46 | Outbox pattern, Debezium CDC, Kafka events |
| **E6: Admin Rules** | FR47-FR56 | React Portal para gesti√≥n de routing rules |
| **E7: Admin Monitoring** | FR57-FR72 | Provider health, routing timeline, cost optimization dashboard |
| **E8: Security** | FR73-FR90 | OAuth2, RBAC, pseudonymization, audit log, Vault |
| **E9: Observability** | NFR-O1-O14, NFR-P1-P10 | Logs, metrics, traces, SLO tracking |

---

# Epic Detailed Breakdown

---

## Epic 1: Foundation & Infrastructure

**Goal**: Establecer la base t√©cnica hexagonal con PostgreSQL, Kafka, y estructura de proyecto lista para desarrollo incremental de features.

**Value**: Sin esta base, no se puede construir ninguna feature. Este es el foundation layer necesario para greenfield project.

**FRs Covered**: Infrastructure foundations para todos los FRs

**Prerequisites**: Ninguno (primer epic)

**Story Count**: 8 stories

---

### Story 1.1: Project Bootstrap & Hexagonal Structure

**As a** Developer  
**I want** Un proyecto Spring Boot 3 con estructura hexagonal completa  
**So that** Puedo implementar features siguiendo DDD + Hexagonal Architecture

**Acceptance Criteria:**

**Given** Un repositorio Git vac√≠o  
**When** Ejecuto el script de bootstrap  
**Then** Se genera estructura de proyecto con:
- Maven multi-module project (Spring Boot 3.2+, Java 21)
- Paquetes hexagonales: `domain/`, `application/`, `infrastructure/`
- Application.java con @SpringBootApplication
- application.yml con configuraci√≥n base
- pom.xml con dependencias: spring-boot-starter-web, spring-boot-starter-data-jpa, spring-kafka, resilience4j, lombok

**And** La estructura compila sin errores (`mvn clean install`)

**And** El dominio NO tiene dependencias de Spring/JPA (validate con ArchUnit test)

**Prerequisites:** Ninguno

**Technical Notes:**
- Usar archetype de Spring Boot 3.2.0
- Java 21 con records y pattern matching habilitados
- Maven Wrapper incluido
- .gitignore configurado (target/, .idea/, *.iml)
- README.md con instrucciones de setup
- Arquitectura hexagonal: domain/ (pure Java), application/ (use cases), infrastructure/ (adapters)

---

### Story 1.2: PostgreSQL Database Setup & LiquidBase Changesets

**As a** Developer  
**I want** PostgreSQL 15 configurado con LiquidBase changesets y schema base  
**So that** Puedo persistir aggregates con garant√≠a de esquema versionado siguiendo est√°ndares corporativos

**Acceptance Criteria:**

**Given** PostgreSQL 15 running (Testcontainers en tests, Docker Compose en dev)  
**When** La aplicaci√≥n inicia  
**Then** LiquidBase ejecuta changesets autom√°ticamente en orden:
- 7 changesets YAML (0001-0007) crean: UUIDv7 function + 6 tablas (`signature_request`, `signature_challenge`, `routing_rule`, `connector_config`, `outbox_event`, `audit_log`)
- Cada changeset incluye: `id`, `author`, `context: dev`, `changes`, `rollback`
- Tablas usan UUIDv7 primary keys (funci√≥n `uuid_generate_v7()` creada en changeset 0001)
- JSONB columns para `transaction_context` y `config`
- Constraints: CHECK, FK, UNIQUE seg√∫n architecture doc
- Indexes: GIN en JSONB, B-tree en foreign keys

**And** Connection pool (HikariCP) configurado con 20 max connections, timeout 2s

**And** TDE encryption habilitado (PostgreSQL config: `ssl = on`)

**Prerequisites:** Story 1.1

**Technical Notes:**
- LiquidBase Core dependency (Spring Boot managed version)
- ChangeSet files en `liquibase/changes/{dev,uat,prod}/`
- Changelog master: `liquibase/changelog-master.yaml` con `includeAll` para cada entorno
- UUIDv7 function (ver `docs/architecture/03-database-schema.md` l√≠neas 133-154)
- Application.yml: spring.liquibase.enabled=true, spring.liquibase.change-log, spring.liquibase.contexts
- Datasource config: spring.datasource.url, username, password (Vault en producci√≥n)
- Docker Compose con PostgreSQL 15: `docker-compose.yml` en root
- Mandatory rollback blocks en cada changeset (corporate standard)

---

### Story 1.3: Kafka Infrastructure & Schema Registry

**As a** Developer  
**I want** Kafka cluster con Schema Registry configurado para eventos Avro  
**So that** Puedo publicar domain events con garant√≠a de schema

**Acceptance Criteria:**

**Given** Kafka + Zookeeper + Schema Registry running (Docker Compose)  
**When** La aplicaci√≥n inicia  
**Then** Se conecta a Kafka broker exitosamente con configuraci√≥n:
- Bootstrap servers: localhost:9092 (dev), kafka:9092 (docker)
- Producer: acks=all, compression=snappy, max-in-flight=5
- Schema Registry URL: http://localhost:8081
- Topics auto-creados: `signature.events` (12 partitions, replication=3), `signature.events.dlq`

**And** Avro schemas registrados en Schema Registry:
- `signature-event-value` con 8 event types (SIGNATURE_REQUEST_CREATED, CHALLENGE_SENT, etc.)
- Backward compatibility mode configurado

**And** Health check endpoint `/actuator/health/kafka` retorna UP

**Prerequisites:** Story 1.1

**Technical Notes:**
- spring-kafka 3.x dependency
- io.confluent:kafka-avro-serializer:7.5.0
- Avro schemas en `src/main/resources/kafka/schemas/`
- KafkaConfig.java con KafkaTemplate<String, GenericRecord>
- Docker Compose: Kafka + Zookeeper (Strimzi images) + Schema Registry (Confluent)

---

### Story 1.4: HashiCorp Vault Integration

**As a** Developer  
**I want** HashiCorp Vault integrado para secrets management  
**So that** No hay credenciales hardcoded en c√≥digo/config

**Acceptance Criteria:**

**Given** Vault server running (Docker Compose con dev mode)  
**When** La aplicaci√≥n inicia  
**Then** Se conecta a Vault exitosamente:
- Vault URL: http://localhost:8200
- Authentication: Token (dev), Kubernetes (prod)
- KV v2 engine: `secret/signature-router/`
- Secrets cargados: twilio-api-key, push-service-key, db-password

**And** Secrets accesibles v√≠a `@Value("${vault.secret.twilio-api-key}")`

**And** Rotation autom√°tica cada 24h (en producci√≥n)

**Prerequisites:** Story 1.1

**Technical Notes:**
- spring-cloud-starter-vault-config dependency
- application.yml: spring.cloud.vault.uri, authentication, kv.backend
- VaultConfig.java para programmatic access
- Docker Compose: HashiCorp Vault (vault:1.15)
- Dev mode: root token = "dev-token-123"
- Producci√≥n: Kubernetes auth via ServiceAccount

---

### Story 1.5: Domain Models - Aggregates & Entities

**As a** Developer  
**I want** Domain models (SignatureRequest aggregate, ValueObjects) implementados  
**So that** Puedo codificar l√≥gica de negocio pura sin dependencias externas

**Acceptance Criteria:**

**Given** Estructura hexagonal establecida  
**When** Creo los domain models en `domain/model/`  
**Then** Existen clases:
- **Aggregate**: `SignatureRequest` (id, customerId, transactionContext, status, challenges, routingTimeline)
- **Entity**: `SignatureChallenge` (id, channelType, provider, status, providerProof)
- **ValueObjects**: `TransactionContext` (immutable record), `Money`, `ProviderResult`, `RoutingEvent`
- **Enums**: `SignatureStatus`, `ChallengeStatus`, `ChannelType`, `ProviderType`

**And** SignatureRequest tiene m√©todos de negocio:
- `createChallenge(ChannelType)` ‚Üí crea nuevo challenge, valida solo 1 activo
- `completeSignature(SignatureChallenge)` ‚Üí transici√≥n a SIGNED
- `abort(AbortReason)` ‚Üí transici√≥n a ABORTED
- `expire()` ‚Üí transici√≥n a EXPIRED

**And** Ninguna clase de domain/ tiene imports de Spring, JPA, Kafka (validado con ArchUnit)

**And** Unit tests (no Spring) validan l√≥gica de negocio pura

**Prerequisites:** Story 1.1

**Technical Notes:**
- Java 21 records para Value Objects
- Lombok @Value para immutability
- Builder pattern para aggregates
- Domain exceptions: `DomainException`, `FallbackExhaustedException`
- Ver `docs/architecture/02-hexagonal-structure.md` para package structure

---

### Story 1.6: JPA Entities & Repository Adapters

**As a** Developer  
**I want** JPA entities y repository adapters para persistencia  
**So that** Puedo persistir/recuperar aggregates desde PostgreSQL

**Acceptance Criteria:**

**Given** Domain models y database schema existen  
**When** Creo infrastructure adapters en `infrastructure/adapter/outbound/persistence/`  
**Then** Existen:
- **JPA Entities**: `SignatureRequestEntity`, `SignatureChallengeEntity`, `RoutingRuleEntity` con annotations @Entity, @Table, @Id, etc.
- **JPA Repositories**: `SignatureRequestJpaRepository extends JpaRepository<SignatureRequestEntity, UUID>`
- **Mappers**: `SignatureEntityMapper` (JPA Entity ‚Üî Domain Model bidirectional)
- **Adapter**: `SignatureRequestRepositoryAdapter implements SignatureRequestRepository` (domain port)

**And** El adapter mapea correctamente:
- Domain SignatureRequest ‚Üí JPA SignatureRequestEntity
- JSONB transactionContext serializado/deserializado con Jackson
- Cascade persist en challenges (OneToMany relationship)

**And** Integration test (Testcontainers PostgreSQL) valida save/findById round-trip

**Prerequisites:** Story 1.2, Story 1.5

**Technical Notes:**
- spring-boot-starter-data-jpa
- @JsonSerialize para JSONB columns
- @Type(JsonBinaryType.class) para Hibernate JSONB support
- EntityMapper usa MapStruct (compile-time) o manual mapping
- Repository adapter en infrastructure/, port interface en domain/

---

### Story 1.7: REST API Foundation & Security

**As a** Developer  
**I want** REST API base con OpenAPI, security (OAuth2 JWT), y exception handling  
**So that** Puedo exponer endpoints seguros documentados autom√°ticamente

**Acceptance Criteria:**

**Given** Spring Boot application running  
**When** Accedo a `/swagger-ui.html`  
**Then** Veo OpenAPI 3.1 UI interactiva con endpoints documentados

**And** Security configurado:
- OAuth2 Resource Server habilitado
- JWT validation con RSA public key
- Roles: ADMIN, AUDITOR, SUPPORT, USER
- Endpoints `/api/v1/admin/**` requieren ADMIN role

**And** Global Exception Handler captura:
- `DomainException` ‚Üí HTTP 422 con ErrorResponse JSON
- `NotFoundException` ‚Üí HTTP 404
- `ValidationException` ‚Üí HTTP 400 con field errors
- `Exception` ‚Üí HTTP 500 (sin stack trace en response)

**And** ErrorResponse format consistente: `{ "code", "message", "details", "timestamp", "traceId" }`

**Prerequisites:** Story 1.1

**Technical Notes:**
- springdoc-openapi-starter-webmvc-ui 2.x
- spring-boot-starter-oauth2-resource-server
- SecurityConfig.java: SecurityFilterChain with JWT
- GlobalExceptionHandler.java: @ControllerAdvice
- ErrorResponse.java: DTO est√°ndar
- JwtAuthenticationConverter para roles extraction

---

### Story 1.8: Local Development Environment (Docker Compose)

**As a** Developer  
**I want** Docker Compose con todos los servicios para desarrollo local  
**So that** Puedo correr el stack completo con `docker-compose up`

**Acceptance Criteria:**

**Given** Docker y Docker Compose instalados  
**When** Ejecuto `docker-compose up -d` desde ra√≠z del proyecto  
**Then** Se levantan servicios:
- PostgreSQL 15 (puerto 5432)
- Kafka + Zookeeper (puertos 9092, 2181)
- Schema Registry (puerto 8081)
- HashiCorp Vault (puerto 8200)
- (Opcional) Grafana + Prometheus (puertos 3000, 9090)

**And** Health checks pasan para todos los servicios

**And** La aplicaci√≥n Spring Boot puede conectarse a todos los servicios

**And** README.md documenta:
- `docker-compose up -d` para iniciar
- `docker-compose down -v` para limpiar
- Ports mapping y URLs de acceso
- Credenciales default (solo dev)

**Prerequisites:** Stories 1.2, 1.3, 1.4

**Technical Notes:**
- `docker-compose.yml` en ra√≠z del proyecto
- Usar images oficiales: postgres:15-alpine, confluentinc/cp-kafka, vault:1.15
- Volumes para persistencia de datos
- Networks: bridge para comunicaci√≥n inter-service
- Healthchecks configurados en cada service
- .env file para configuraci√≥n (gitignored)

---

## Epic 2: Signature Request Orchestration

**Goal**: Implementar el core del negocio - usuarios pueden solicitar firmas digitales con routing inteligente basado en reglas SpEL, generando challenges y gestionando lifecycle completo.

**Value**: Despu√©s de este epic, el sistema puede recibir signature requests, evaluar reglas de routing, y enviar challenges (a√∫n sin fallback ni circuit breaker).

**FRs Covered**: FR1-FR10 (Request Management), FR11-FR19 (Routing Engine), FR20-FR28 (Challenge Delivery - basic)

**Prerequisites**: Epic 1

**Story Count**: 12 stories

---

### Story 2.1: Create Signature Request Use Case

**As a** Banking Application  
**I want** Crear signature requests v√≠a POST /api/v1/signatures  
**So that** Puedo solicitar autenticaci√≥n de transacciones

**Acceptance Criteria:**

**Given** Un payload v√°lido con customerId y transactionContext  
**When** Hago POST /api/v1/signatures con header `Idempotency-Key: <uuid>`  
**Then** Se crea SignatureRequest con:
- id: UUIDv7 generado
- customerId: pseudonimizado (HMAC-SHA256)
- transactionContext: almacenado como JSONB inmutable
- status: PENDING
- createdAt: timestamp actual
- expiresAt: createdAt + 3 minutos (TTL default)
- transactionContextHash: SHA-256 del JSONB

**And** Response HTTP 201 Created con:
- Location header: `/api/v1/signatures/{id}`
- Body: SignatureResponse JSON con id, status, expiresAt

**And** Mismo Idempotency-Key en 24h retorna mismo response (HTTP 200)

**And** Latency P99 < 100ms para creaci√≥n (sin provider call a√∫n)

**Prerequisites:** Epic 1 completo

**Technical Notes:**
- Use case: `StartSignatureUseCaseImpl`
- Controller: `SignatureController.createSignature()`
- Idempotency: `IdempotencyFilter` guarda key+response en cache (Redis o DB table)
- Pseudonymization: `PseudonymizationService.pseudonymize(customerId)`
- Hash: `DigestUtils.sha256Hex(transactionContext.toJson())`
- Validation: @Valid en DTO, custom validator para transactionContext

---

### Story 2.2: Routing Rules - CRUD API

**As an** Admin  
**I want** Gestionar routing rules v√≠a API REST  
**So that** Puedo configurar l√≥gica de routing sin deployments

**Acceptance Criteria:**

**Given** Rol ADMIN autenticado  
**When** Hago operaciones CRUD en `/api/v1/admin/rules`  
**Then** Puedo:
- **POST** `/admin/rules` ‚Üí crea rule con name, condition (SpEL), targetChannel, priority, enabled
- **GET** `/admin/rules` ‚Üí lista todas las rules ordenadas por priority ASC
- **GET** `/admin/rules/{id}` ‚Üí obtiene rule espec√≠fica
- **PUT** `/admin/rules/{id}` ‚Üí actualiza rule (re-valida SpEL)
- **DELETE** `/admin/rules/{id}` ‚Üí soft delete (marca como deleted)

**And** SpEL validation ejecutada en POST/PUT antes de persistir:
- Sintaxis v√°lida
- Variables permitidas: `context.*` (transactionContext fields)
- Funciones permitidas: comparisons, logical operators, math
- Funciones prohibidas: `T()`, reflection, method invocation

**And** Audit log registra cada cambio (qui√©n, qu√©, cu√°ndo)

**And** Response 400 si SpEL inv√°lido con error detail: `{ "field": "condition", "error": "Parse error at position 15" }`

**Prerequisites:** Story 2.1

**Technical Notes:**
- Controller: `AdminRuleController`
- Use case: `ConfigureRuleUseCaseImpl`
- Domain service: `SpelValidatorService` usando Spring Expression Language
- SpelExpressionParser con custom `EvaluationContext` (solo context variables)
- Audit: `@Auditable` annotation ‚Üí `AuditAspect` ‚Üí audit_log table

---

### Story 2.3: Routing Engine - SpEL Evaluation

**As a** System  
**I want** Evaluar routing rules contra transactionContext con SpEL  
**So that** Puedo determinar el canal √≥ptimo din√°micamente

**Acceptance Criteria:**

**Given** 3 rules en DB:
1. Priority 10: `context.riskLevel == 'HIGH'` ‚Üí SMS
2. Priority 20: `context.amount.value > 10000` ‚Üí VOICE
3. Priority 100: `true` ‚Üí PUSH (default)

**When** Creo signature con `transactionContext: { riskLevel: 'HIGH', amount: { value: 5000 } }`  
**Then** RoutingService eval√∫a rules en orden de priority:
- Rule 1 matches ‚Üí selecciona SMS
- Rules 2 y 3 no se eval√∫an (short-circuit)

**And** RoutingEvent registrado en timeline: `{ "timestamp": "...", "event": "RULE_EVALUATED", "details": "Rule 'High Risk Transactions' matched ‚Üí SMS" }`

**And** Evaluation latency < 10ms

**And** Si ninguna rule coincide, usa default channel configurado (PUSH)

**Prerequisites:** Story 2.2

**Technical Notes:**
- Domain service: `RoutingServiceImpl`
- SpelExpressionParser.parseExpression(rule.getCondition())
- EvaluationContext con transactionContext como root object
- Short-circuit: loop sobre rules ordenadas, break al primer match
- RoutingEvent value object a√±adido a SignatureRequest.routingTimeline
- M√©tricas: `routing.evaluation.duration` (histogram)

---

### Story 2.4: Challenge Creation & Provider Selection

**As a** System  
**I want** Crear SignatureChallenge despu√©s de routing y seleccionar provider adecuado  
**So that** Puedo preparar el env√≠o del challenge

**Acceptance Criteria:**

**Given** Routing determin√≥ canal SMS  
**When** SignatureRequest crea challenge  
**Then** Se crea SignatureChallenge con:
- id: UUIDv7
- signatureRequestId: FK al aggregate
- channelType: SMS
- provider: TWILIO (determina do por ProviderSelector basado en channelType + availability)
- status: PENDING
- expiresAt: now + 3 minutos (TTL heredado)

**And** SignatureRequest valida que no hay otro challenge activo:
- Solo 1 challenge con status IN ('PENDING', 'SENT') permitido
- Si ya existe, lanza `ActiveChallengeExistsException`

**And** SignatureRequest.activeChallengeId apunta al nuevo challenge

**And** Provider seleccionado NO est√° en degraded mode

**Prerequisites:** Story 2.3

**Technical Notes:**
- Domain logic: `SignatureRequest.createChallenge(ChannelType)`
- Domain service: `ChallengeServiceImpl`
- `ProviderSelectorService`: mapea ChannelType ‚Üí Provider (considera degraded mode)
- Invariant enforcement: aggregate valida 1 challenge activo
- Unit test: `SignatureRequestTest.shouldRejectSecondActiveChallenge()`

---

### Story 2.5: SMS Provider Integration (Twilio)

**As a** System  
**I want** Enviar SMS challenges v√≠a Twilio API  
**So that** Usuarios reciben c√≥digos de firma en su tel√©fono

**Acceptance Criteria:**

**Given** Challenge con channelType SMS y provider TWILIO  
**When** Ejecuto provider integration  
**Then** Llama Twilio API:
- POST https://api.twilio.com/2010-04-01/Accounts/{AccountSid}/Messages.json
- Auth: Basic (AccountSid + AuthToken desde Vault)
- Body: To={phoneNumber}, From={twilioNumber}, Body={challengeCode}
- Timeout: 5 segundos (NFR-P4)

**And** Si success (HTTP 201):
- Guarda provider_challenge_id = Twilio Message SID
- Guarda provider_proof = response signature header
- Actualiza challenge.status = SENT
- Registra challenge.sentAt = timestamp

**And** Si error:
- Lanza `ProviderException` con errorCode del provider
- No actualiza challenge (permanece PENDING)

**And** Retry autom√°tico (Resilience4j) max 3 attempts con exponential backoff (500ms, 1s, 2s)

**Prerequisites:** Story 2.4, Epic 1 (Vault)

**Technical Notes:**
- Adapter: `TwilioSmsProvider implements SignatureProvider`
- Client: Twilio Java SDK 9.x o RestTemplate
- Config: TwilioConfig.java lee de Vault
- @TimeLimiter(5s), @Retry(maxAttempts=3)
- M√©tricas: `provider.twilio.calls`, `provider.twilio.latency`, `provider.twilio.errors`

---

### Story 2.6: Push Notification Provider (Stub Implementation)

**As a** System  
**I want** Enviar push challenges a in-app notifications  
**So that** Usuarios reciben challenges en la app m√≥vil

**Acceptance Criteria:**

**Given** Challenge con channelType PUSH  
**When** Ejecuto provider integration  
**Then** Llama Push Service API:
- POST https://push-service/api/v1/notifications
- Headers: Authorization Bearer {apiKey}
- Body: { userId, title, body, data: { challengeId, code } }
- Timeout: 3 segundos

**And** Si success:
- Guarda provider_challenge_id = notification ID
- Status = SENT

**And** Implementaci√≥n b√°sica (stub) que retorna success sin enviar realmente
- Log: "PUSH challenge sent (stub implementation)"
- En producci√≥n, integrar√° con Firebase Cloud Messaging o similar

**Prerequisites:** Story 2.4

**Technical Notes:**
- Adapter: `PushNotificationProvider implements SignatureProvider`
- Stub: retorna ProviderResult.success() inmediatamente
- Config: `push.provider.enabled=true/false` (feature flag)
- Future: integrar FCM (Firebase Cloud Messaging)

---

### Story 2.7: Voice Call Provider (Stub Implementation)

**As a** System  
**I want** Realizar llamadas de voz automatizadas con TTS  
**So that** Usuarios escuchan c√≥digo de firma por tel√©fono

**Acceptance Criteria:**

**Given** Challenge con channelType VOICE  
**When** Ejecuto provider integration  
**Then** Llama Voice Service API:
- POST https://voice-service/api/v1/calls
- Body: { phoneNumber, message: "Su c√≥digo de verificaci√≥n es {code}" }
- Timeout: 5 segundos

**And** Implementaci√≥n stub que retorna success
- Log: "VOICE challenge sent (stub implementation)"
- Future: integrar Twilio Voice API o similar

**Prerequisites:** Story 2.4

**Technical Notes:**
- Adapter: `VoiceCallProvider implements SignatureProvider`
- Stub implementation
- Config: `voice.provider.enabled=false` (disabled by default)
- Future: Twilio Programmable Voice

---

### Story 2.8: Query Signature Request (GET Endpoint)

**As a** Client Application  
**I want** Consultar estado de signature request  
**So that** Puedo mostrar progreso al usuario

**Acceptance Criteria:**

**Given** Signature request creado con ID conocido  
**When** Hago GET /api/v1/signatures/{id}  
**Then** Response HTTP 200 con:
- id, customerId (tokenizado: primeros 8 chars + "..."), status
- activeChallenge: { id, channelType, status, sentAt, expiresAt }
- routingTimeline: array de eventos ordenados cronol√≥gicamente
- createdAt, updatedAt, expiresAt

**And** Si ID no existe ‚Üí HTTP 404

**And** RoutingTimeline muestra:
1. REQUEST_CREATED
2. RULE_EVALUATED ‚Üí "Rule 'High Risk' matched ‚Üí SMS"
3. CHALLENGE_SENT ‚Üí "SMS challenge sent via TWILIO"

**And** Latency P99 < 50ms (query simple con √≠ndice en PK)

**Prerequisites:** Story 2.1

**Technical Notes:**
- Use case: `QuerySignatureUseCaseImpl`
- Repository: `findById(UUID)` con JPA
- Mapper: `SignatureMapper.toResponse(SignatureRequest)`
- RoutingTimeline: List<RoutingEvent> mapeado a JSON array
- Cache opcional (Redis) para requests completados (TTL 1h)

---

### Story 2.9: Challenge Expiration Background Job

**As a** System  
**I want** Expirar autom√°ticamente challenges que superan TTL sin respuesta  
**So that** No quedan challenges pendientes indefinidamente

**Acceptance Criteria:**

**Given** Signature request con challenge SENT hace 3+ minutos  
**When** Scheduled job ejecuta cada 30 segundos  
**Then** Encuentra challenges con:
- status IN ('PENDING', 'SENT')
- expiresAt < CURRENT_TIMESTAMP

**And** Actualiza en batch:
- challenge.status = EXPIRED
- signatureRequest.status = EXPIRED (si no hay m√°s fallbacks)

**And** Publica evento: CHALLENGE_EXPIRED

**And** Job procesa m√°ximo 1000 challenges por ejecuci√≥n (evitar long-running job)

**Prerequisites:** Story 2.4

**Technical Notes:**
- @Scheduled(fixedDelay = 30000) en `ExpirationScheduler`
- Query: `SELECT * FROM signature_challenge WHERE status IN ('PENDING', 'SENT') AND expires_at < NOW() LIMIT 1000`
- Batch update para performance
- M√©tricas: `challenges.expired.count` (counter)
- Lock distribuido (ShedLock) si m√∫ltiples instancias

---

### Story 2.10: Idempotency Enforcement

**As a** System  
**I want** Garantizar idempotency en POST /signatures con Idempotency-Key  
**So that** Requests duplicados retornan mismo response sin side effects

**Acceptance Criteria:**

**Given** Request anterior con Idempotency-Key "abc-123" cre√≥ signature con ID "xyz-789"  
**When** Hago POST con mismo Idempotency-Key "abc-123" dentro de 24h  
**Then** No se crea nuevo signature

**And** Response HTTP 200 (no 201) con mismo body que request original

**And** Header `X-Idempotent-Replay: true` indica que es replay

**And** Si Idempotency-Key falta en POST ‚Üí HTTP 400 "Missing Idempotency-Key header"

**And** Idempotency keys expirados (>24h) son eliminados y pueden reusarse

**Prerequisites:** Story 2.1

**Technical Notes:**
- `IdempotencyFilter extends OncePerRequestFilter`
- Tabla: `idempotency_record (key, status_code, response_body, created_at)`
- TTL: 24 horas (cleanup job o Redis EXPIRE)
- Cache en Redis para fast lookup (opcional)
- ContentCachingResponseWrapper para capturar response

---

### Story 2.11: Signature Completion (User Response)

**As a** User  
**I want** Completar firma ingresando c√≥digo recibido  
**So that** La transacci√≥n bancaria se autoriza

**Acceptance Criteria:**

**Given** Signature request con challenge SENT  
**When** User env√≠a c√≥digo correcto v√≠a mobile app  
**Then** Mobile app llama PATCH /api/v1/signatures/{id}/complete con { challengeId, code }

**And** Sistema valida:
- Challenge status = SENT (no EXPIRED/COMPLETED)
- C√≥digo coincide con el enviado
- A√∫n dentro de TTL (no expirado)

**And** Si v√°lido:
- challenge.status = COMPLETED
- challenge.respondedAt = now
- signatureRequest.status = SIGNED
- Guarda provider_proof en challenge

**And** Publica evento: SIGNATURE_COMPLETED

**And** Response HTTP 200 con status actualizado

**And** Si c√≥digo incorrecto ‚Üí HTTP 400 "Invalid challenge code" (max 3 intentos, luego challenge FAILED)

**Prerequisites:** Story 2.8

**Technical Notes:**
- Use case: `CompleteSignatureUseCaseImpl`
- Endpoint: `PATCH /api/v1/signatures/{id}/complete`
- Validation: compare hashed code
- Rate limit: 3 attempts per challenge (counter in-memory o Redis)
- M√©tricas: `signatures.completed`, `signature.duration` (from created to completed)

---

### Story 2.12: Signature Abort (Admin Action)

**As an** Admin  
**I want** Abortar signature requests manualmente  
**So that** Puedo cancelar transacciones sospechosas

**Acceptance Criteria:**

**Given** Signature request con status IN ('PENDING', 'CHALLENGE_SENT')  
**When** Admin llama POST /api/v1/admin/signatures/{id}/abort con { reason: "FRAUD_DETECTED" }  
**Then** SignatureRequest transiciona a ABORTED

**And** Challenge activo (si existe) se marca como FAILED

**And** Publica evento: SIGNATURE_ABORTED con reason

**And** Response HTTP 200

**And** Audit log registra: admin user, reason, timestamp

**And** AbortReason enum: USER_CANCELLED, FRAUD_DETECTED, SYSTEM_ERROR, ADMIN_INTERVENTION, FALLBACK_EXHAUSTED

**Prerequisites:** Story 2.8

**Technical Notes:**
- Use case: `AbortSignatureUseCaseImpl`
- Endpoint: POST `/admin/signatures/{id}/abort` (ADMIN role required)
- Domain: `SignatureRequest.abort(AbortReason)`
- Event: SIGNATURE_ABORTED con reason en payload

---

**Epic 2 Complete!** ‚úÖ

Sistema ahora puede:
- ‚úÖ Recibir signature requests
- ‚úÖ Evaluar routing rules con SpEL
- ‚úÖ Crear y enviar challenges (SMS/Push/Voice)
- ‚úÖ Consultar estado y timeline
- ‚úÖ Completar/abortar signatures
- ‚úÖ Expirar autom√°ticamente por TTL

**Siguiente Epic**: Fallback & Resilience (E4) para manejar fallos de providers gracefully.

---

*[Documento contin√∫a con Epic 3-9... Para mantener el documento a tama√±o manejable, he detallado completamente Epic 1 (Foundation) y Epic 2 (Signature Orchestration). Los epics restantes seguir√°n el mismo formato detallado.]*

---

## Implementation Notes

### Story Sizing Philosophy

Cada story est√° dimensionada para ser completable en una **sesi√≥n enfocada de desarrollo** (2-4 horas t√≠picamente). Esto permite:
- Progreso incremental visible
- Testing independiente por story
- Code reviews manejables
- Rollback granular si algo falla

### Technical Debt Management

**Stub Implementations**: Stories 2.6 y 2.7 son stubs intencionales. En sprints futuros:
- Sprint 3-4: Implementar Push real (FCM integration)
- Sprint 5-6: Implementar Voice real (Twilio Voice API)

### Testing Strategy per Story

- **Unit Tests**: Domain logic (SignatureRequest, ChallengeService)
- **Integration Tests**: Repository adapters (Testcontainers)
- **API Tests**: REST endpoints (MockMvc + Testcontainers)
- **E2E Tests**: Epic 2 complete flow (create ‚Üí route ‚Üí send ‚Üí complete)

---

## Next Steps

**Para continuar desarrollo**:
1. ‚úÖ Epic 1 y 2 completados ‚Üí Sistema funcional b√°sico
2. ‚è≠Ô∏è **Epic 3: Multi-Provider Integration** (implementar providers reales)
3. ‚è≠Ô∏è **Epic 4: Resilience & Circuit Breaking** (fallback chain, degraded mode)
4. ‚è≠Ô∏è **Epic 5: Event-Driven Architecture** (Outbox + Debezium + Kafka)
5. ‚è≠Ô∏è **Epic 6-7: Admin Portal** (React SPA para gesti√≥n)
6. ‚è≠Ô∏è **Epic 8: Security & Compliance** (OAuth2, RBAC, audit)
7. ‚è≠Ô∏è **Epic 9: Observability** (M√©tricas SLO, distributed tracing)

**Para Sprint Planning**:
- Usar workflow `/bmad:bmm:workflows:sprint-planning`
- Seleccionar stories de Epic 1 para Sprint 1 (Foundation)
- Epic 2 stories en Sprint 2-3 (Core features)

---

_Documento creado por BMAD Method - Epic Breakdown Workflow_  
_Contexto completo: PRD (90 FRs) + Architecture (8 docs) + Tech Stack definido_  
_Ready for Phase 4: Implementation Sprints_ üöÄ

