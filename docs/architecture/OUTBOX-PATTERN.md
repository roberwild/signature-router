# Outbox Pattern Implementation

**Status:** âœ… Implemented (Story 5.1)  
**Epic:** Epic 5 - Event-Driven Architecture  
**Version:** 1.0  
**Date:** 2025-11-28  

---

## ðŸ“‹ Overview

The Signature Router implements the **Outbox Pattern** to guarantee **at-least-once** delivery of domain events to Kafka with **zero data loss** and **transactional consistency**.

### Why Outbox Pattern?

**Problem:**
- Publishing events directly to Kafka during transaction is **NOT atomic**
- If Kafka is down â†’ event lost (data loss)
- If transaction rolls back after Kafka publish â†’ inconsistent state

**Solution:**
- Persist events to `outbox_event` table **in same transaction** as aggregate
- Debezium CDC connector reads outbox table (PostgreSQL WAL)
- Events published to Kafka asynchronously with **guaranteed delivery**

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Use Cases)                               â”‚
â”‚                                                              â”‚
â”‚  @Transactional                                              â”‚
â”‚  public void completeSignature() {                          â”‚
â”‚      repository.save(signatureRequest);  // (1)             â”‚
â”‚      eventPublisher.publish(event);       // (2)            â”‚
â”‚  }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ TX COMMIT â†’ Both (1) and (2) persisted
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Database                                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ signature_request   â”‚  â”‚ outbox_event        â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
â”‚  â”‚ id                  â”‚  â”‚ id                  â”‚          â”‚
â”‚  â”‚ status = SIGNED     â”‚  â”‚ event_type          â”‚          â”‚
â”‚  â”‚ signed_at           â”‚  â”‚ payload (JSONB)     â”‚          â”‚
â”‚  â”‚ ...                 â”‚  â”‚ published_at = NULL â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Debezium reads PostgreSQL WAL
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Debezium CDC Connector                                      â”‚
â”‚                                                              â”‚
â”‚  1. Detect new row in outbox_event (via WAL)                â”‚
â”‚  2. Transform to Kafka event                                â”‚
â”‚  3. Publish to Kafka topic: signature.events                â”‚
â”‚  4. Update published_at = NOW()                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic: signature.events                               â”‚
â”‚                                                              â”‚
â”‚  Partition Key = aggregateId (ordering guarantee)           â”‚
â”‚  Schema = Avro (Schema Registry validation)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¾ Database Schema

### outbox_event Table

```sql
CREATE TABLE outbox_event (
    id UUID PRIMARY KEY,                    -- UUIDv7 (time-ordered)
    aggregate_id UUID NOT NULL,             -- SignatureRequest ID
    aggregate_type VARCHAR(100) NOT NULL,   -- "SignatureRequest"
    event_type VARCHAR(100) NOT NULL,       -- "SIGNATURE_COMPLETED"
    payload JSONB NOT NULL,                 -- Event JSON
    payload_hash VARCHAR(64),               -- SHA-256 for integrity
    created_at TIMESTAMPTZ NOT NULL,        -- Application timestamp
    published_at TIMESTAMPTZ                -- Debezium timestamp (NULL until published)
);

-- Index for pending events (Debezium reads these)
CREATE INDEX idx_outbox_created_at 
    ON outbox_event(created_at ASC) 
    WHERE published_at IS NULL;

-- Index for aggregate timeline queries
CREATE INDEX idx_outbox_aggregate 
    ON outbox_event(aggregate_id, aggregate_type);
```

---

## ðŸ“ Code Usage

### Publishing Events in Use Cases

```java
@Service
@RequiredArgsConstructor
public class CompleteSignatureUseCaseImpl implements CompleteSignatureUseCase {
    
    private final SignatureRequestRepository repository;
    private final EventPublisher eventPublisher;
    private final CorrelationIdProvider correlationIdProvider;
    
    @Override
    @Transactional  // CRITICAL: Events MUST be published within TX
    public void execute(UUID requestId, String code) {
        
        // 1. Load aggregate
        SignatureRequest request = repository.findById(requestId)
            .orElseThrow(() -> new NotFoundException("Not found"));
        
        // 2. Business logic
        request.complete(code);
        
        // 3. Save aggregate (state change)
        repository.save(request);
        
        // 4. Publish event (same TX)
        SignatureCompletedEvent event = SignatureCompletedEvent.create(
            request.getId(),
            request.getChallengeId(),
            request.getChannel(),
            correlationIdProvider.getCorrelationId()
        );
        
        eventPublisher.publish(event);  // Persisted to outbox_event
        
        // TX COMMIT â†’ Both aggregate + event guaranteed persisted
    }
}
```

### Creating Domain Events

All events implement `DomainEvent` interface:

```java
public record SignatureCompletedEvent(
    UUID eventId,
    UUID signatureRequestId,
    UUID challengeId,
    ChannelType channelType,
    Instant completedAt,
    String correlationId
) implements DomainEvent {
    
    @Override
    public UUID getAggregateId() {
        return signatureRequestId;
    }
    
    @Override
    public String getEventType() {
        return "SIGNATURE_COMPLETED";
    }
    
    // Factory method
    public static SignatureCompletedEvent create(...) {
        return new SignatureCompletedEvent(
            UuidCreator.getTimeOrderedEpoch(),  // UUIDv7
            signatureRequestId,
            challengeId,
            channelType,
            Instant.now(),
            correlationId
        );
    }
}
```

---

## ðŸ”§ Configuration

### Debezium Connector

Deploy to Kafka Connect cluster:

```json
{
  "name": "signature-outbox-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.dbname": "signature_db",
    "plugin.name": "pgoutput",
    
    "table.include.list": "public.outbox_event",
    
    "transforms": "outbox",
    "transforms.outbox.type": "io.debezium.transforms.outbox.EventRouter",
    "transforms.outbox.table.field.event.key": "aggregate_id",
    "transforms.outbox.table.field.event.type": "event_type",
    "transforms.outbox.table.field.event.payload": "payload",
    "transforms.outbox.route.topic.replacement": "signature.events",
    
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "value.converter.schema.registry.url": "http://localhost:8081"
  }
}
```

### PostgreSQL Publication

```sql
-- Create publication for Debezium
CREATE PUBLICATION signature_outbox_publication 
    FOR TABLE outbox_event;

-- Verify replication slot
SELECT * FROM pg_replication_slots;
```

---

## ðŸ“Š Monitoring & Metrics

### Prometheus Metrics

```yaml
# Counter: Total events created
outbox.events.created.total{event_type="SIGNATURE_COMPLETED"} 1543

# Gauge: Pending events (not yet published)
outbox.events.pending 12

# Histogram: Publish duration to outbox
outbox.publish.duration.seconds_count 1543
outbox.publish.duration.seconds{quantile="0.99"} 0.025
```

### Grafana Dashboards

**Panel 1: Events Created Rate**
```promql
rate(outbox_events_created_total[5m])
```

**Panel 2: Pending Events (Debezium Lag)**
```promql
outbox_events_pending
```

**Panel 3: Publish Latency P99**
```promql
histogram_quantile(0.99, outbox_publish_duration_seconds_bucket)
```

### Alerts

```yaml
alerts:
  - name: OutboxEventsNotPublished
    expr: outbox_events_pending > 100
    for: 5m
    severity: HIGH
    action: Check Debezium connector status
    
  - name: DebeziumConnectorDown
    expr: debezium_connector_status != 1
    for: 1m
    severity: CRITICAL
    action: Page on-call engineer
```

---

## ðŸ§ª Testing

### Unit Tests

```java
@Test
void shouldPersistEventToOutbox() {
    // Given
    DomainEvent event = SignatureCompletedEvent.create(...);
    
    // When
    publisher.publish(event);
    
    // Then
    verify(outboxRepository).save(argThat(outbox -> 
        outbox.getEventType().equals("SIGNATURE_COMPLETED") &&
        outbox.getPublishedAt() == null
    ));
}
```

### Integration Tests

```java
@SpringBootTest
@Testcontainers
class OutboxPatternIT {
    
    @Container
    static PostgreSQLContainer<?> postgres = ...;
    
    @Test
    void shouldGuaranteeAtomicity_whenTransactionRollback() {
        // Given
        DomainEvent event = SignatureCompletedEvent.create(...);
        
        // When - Simulate rollback
        assertThrows(RuntimeException.class, () -> {
            transactionTemplate.execute(status -> {
                eventPublisher.publish(event);
                throw new RuntimeException("Rollback");
            });
        });
        
        // Then - NO event in outbox
        assertThat(outboxRepository.count()).isZero();
    }
}
```

---

## ðŸš¨ Troubleshooting

### Issue: Pending Events Growing

**Symptom:** `outbox_events_pending` metric increasing

**Diagnosis:**
```bash
# Check Debezium connector status
curl http://localhost:8083/connectors/signature-outbox-connector/status

# Check PostgreSQL replication slot
SELECT * FROM pg_replication_slots WHERE slot_name = 'debezium';
```

**Resolution:**
```bash
# Restart Debezium connector
curl -X POST http://localhost:8083/connectors/signature-outbox-connector/restart
```

### Issue: Outbox Table Bloat

**Symptom:** `outbox_event` table size > 10GB

**Resolution:**
```sql
-- Purge published events older than 7 days
DELETE FROM outbox_event
WHERE published_at IS NOT NULL
  AND published_at < CURRENT_TIMESTAMP - INTERVAL '7 days';

-- Run VACUUM to reclaim space
VACUUM FULL outbox_event;
```

### Issue: Duplicate Events in Kafka

**Symptom:** Same event published multiple times

**Explanation:** Outbox pattern guarantees **at-least-once** delivery, NOT exactly-once.

**Solution:** Consumers MUST be **idempotent**:
```java
@KafkaListener(topics = "signature.events")
public void handleEvent(SignatureEvent event) {
    // Check if already processed (use eventId as deduplication key)
    if (processedEvents.contains(event.getEventId())) {
        log.warn("Duplicate event ignored: {}", event.getEventId());
        return;
    }
    
    // Process event
    processEvent(event);
    processedEvents.add(event.getEventId());
}
```

---

## ðŸ“š References

- **Pattern:** [Microservices.io - Transactional Outbox](https://microservices.io/patterns/data/transactional-outbox.html)
- **Debezium:** [Official Documentation](https://debezium.io/documentation/)
- **Story:** `docs/sprint-artifacts/5-1-outbox-pattern-implementation.md`
- **Tech Spec:** `docs/sprint-artifacts/tech-spec-epic-5.md`

---

**Status:** âœ… **PRODUCTION READY**

**Next Steps:**
- Story 5.2: Deploy Debezium connector
- Story 5.4: Register Avro schemas in Schema Registry
- Story 5.6: Implement event consumers (Analytics, Audit)

